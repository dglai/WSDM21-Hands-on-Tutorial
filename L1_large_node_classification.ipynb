{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nTraining GNN with Neighbor Sampling for Node Classification\n===========================================================\n\nThis tutorial shows how to train a multi-layer GraphSAGE for node\nclassification on ``ogbn-arxiv`` provided by `Open Graph\nBenchmark (OGB) <https://ogb.stanford.edu/>`__. The dataset contains around\n170 thousand nodes and 1 million edges.\n\nBy the end of this tutorial, you will be able to\n\n-  Train a GNN model for node classification on a single GPU with DGL's\n   neighbor sampling components.\n\nThis tutorial assumes that you have read the :doc:`Introduction of Neighbor\nSampling for GNN Training <L0_neighbor_sampling_overview>`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading Dataset\n---------------\n\nOGB already prepared the data as DGL graph.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import dgl\nimport torch\nimport numpy as np\nfrom ogb.nodeproppred import DglNodePropPredDataset\n\ndataset = DglNodePropPredDataset('ogbn-arxiv')\ndevice = 'cpu'      # change to 'cuda' for GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "OGB dataset is a collection of graphs and their labels. ``ogbn-arxiv``\ndataset only contains a single graph. So you can\nsimply get the graph and its node labels like this:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph, node_labels = dataset[0]\n# Add reverse edges since ogbn-arxiv is unidirectional.\ngraph = dgl.add_reverse_edges(graph)\ngraph.ndata['label'] = node_labels[:, 0]\nprint(graph)\nprint(node_labels)\n\nnode_features = graph.ndata['feat']\nnum_features = node_features.shape[1]\nnum_classes = (node_labels.max() + 1).item()\nprint('Number of classes:', num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can get the training-validation-test split of the nodes with\n``get_split_idx`` method.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "idx_split = dataset.get_idx_split()\ntrain_nids = idx_split['train']\nvalid_nids = idx_split['valid']\ntest_nids = idx_split['test']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "How DGL Handles Computation Dependency\n--------------------------------------\n\nIn the :doc:`previous tutorial <L0_neighbor_sampling_overview>`, you\nhave seen that the computation dependency for message passing of a\nsingle node can be described as a series of *message flow graphs* (MFG).\n\n|image1|\n\n.. |image1| image:: https://data.dgl.ai/tutorial/img/bipartite.gif\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defining Neighbor Sampler and Data Loader in DGL\n------------------------------------------------\n\nDGL provides tools to iterate over the dataset in minibatches\nwhile generating the computation dependencies to compute their outputs\nwith the MFGs above. For node classification, you can use\n``dgl.dataloading.NodeDataLoader`` for iterating over the dataset.\nIt accepts a sampler object to control how to generate the computation\ndependencies in the form of MFGs.  DGL provides\nimplementations of common sampling algorithms such as\n``dgl.dataloading.MultiLayerNeighborSampler`` which randomly picks\na fixed number of neighbors for each node.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>To write your own neighbor sampler, please refer to `this user\n   guide section <guide-minibatch-customizing-neighborhood-sampler>`.</p></div>\n\nThe syntax of ``dgl.dataloading.NodeDataLoader`` is mostly similar to a\nPyTorch ``DataLoader``, with the addition that it needs a graph to\ngenerate computation dependency from, a set of node IDs to iterate on,\nand the neighbor sampler you defined.\n\nLet\u2019s say that each node will gather messages from 4 neighbors on each\nlayer. The code defining the data loader and neighbor sampler will look\nlike the following.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sampler = dgl.dataloading.MultiLayerNeighborSampler([4, 4])\ntrain_dataloader = dgl.dataloading.NodeDataLoader(\n    # The following arguments are specific to NodeDataLoader.\n    graph,              # The graph\n    train_nids,         # The node IDs to iterate over in minibatches\n    sampler,            # The neighbor sampler\n    device=device,      # Put the sampled MFGs on CPU or GPU\n    # The following arguments are inherited from PyTorch DataLoader.\n    batch_size=1024,    # Batch size\n    shuffle=True,       # Whether to shuffle the nodes for every epoch\n    drop_last=False,    # Whether to drop the last incomplete batch\n    num_workers=0       # Number of sampler processes\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can iterate over the data loader and see what it yields.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "input_nodes, output_nodes, mfgs = example_minibatch = next(iter(train_dataloader))\nprint(example_minibatch)\nprint(\"To compute {} nodes' outputs, we need {} nodes' input features\".format(len(output_nodes), len(input_nodes)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``NodeDataLoader`` gives us three items per iteration.\n\n-  An ID tensor for the input nodes, i.e., nodes whose input features\n   are needed on the first GNN layer for this minibatch.\n-  An ID tensor for the output nodes, i.e. nodes whose representations\n   are to be computed.\n-  A list of MFGs storing the computation dependencies\n   for each GNN layer.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can get the source and destination node IDs of the MFGs\nand verify that the first few source nodes are always the same as the destination\nnodes.  As we described in the :doc:`overview <L0_neighbor_sampling_overview>`,\ndestination nodes' own features from the previous layer may also be necessary in\nthe computation of the new features.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mfg_0_src = mfgs[0].srcdata[dgl.NID]\nmfg_0_dst = mfgs[0].dstdata[dgl.NID]\nprint(mfg_0_src)\nprint(mfg_0_dst)\nprint(torch.equal(mfg_0_src[:mfgs[0].num_dst_nodes()], mfg_0_dst))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defining Model\n--------------\n\nLet\u2019s consider training a 2-layer GraphSAGE with neighbor sampling. The\nmodel can be written as follows:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\nimport torch.nn.functional as F\nfrom dgl.nn import SAGEConv\n\nclass Model(nn.Module):\n    def __init__(self, in_feats, h_feats, num_classes):\n        super(Model, self).__init__()\n        self.conv1 = SAGEConv(in_feats, h_feats, aggregator_type='mean')\n        self.conv2 = SAGEConv(h_feats, num_classes, aggregator_type='mean')\n        self.h_feats = h_feats\n\n    def forward(self, mfgs, x):\n        # Lines that are changed are marked with an arrow: \"<---\"\n\n        h_dst = x[:mfgs[0].num_dst_nodes()]  # <---\n        h = self.conv1(mfgs[0], (x, h_dst))  # <---\n        h = F.relu(h)\n        h_dst = h[:mfgs[1].num_dst_nodes()]  # <---\n        h = self.conv2(mfgs[1], (h, h_dst))  # <---\n        return h\n\nmodel = Model(num_features, 128, num_classes).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you compare against the code in the\n:doc:`introduction <../blitz/1_introduction>`, you will notice several\ndifferences:\n\n-  **DGL GNN layers on MFGs**. Instead of computing on the\n   full graph:\n\n   .. code:: python\n\n      h = self.conv1(g, x)\n\n   you only compute on the sampled MFG:\n\n   .. code:: python\n\n      h = self.conv1(mfgs[0], (x, h_dst))\n\n   All DGL\u2019s GNN modules support message passing on MFGs,\n   where you supply a pair of features, one for source nodes and another\n   for destination nodes.\n\n-  **Feature slicing for self-dependency**. There are statements that\n   perform slicing to obtain the previous-layer representation of the\n    nodes:\n\n   .. code:: python\n\n      h_dst = x[:mfgs[0].num_dst_nodes()]\n\n   ``num_dst_nodes`` method works with MFGs, where it will\n   return the number of destination nodes.\n\n   Since the first few source nodes of the yielded MFG are\n   always the same as the destination nodes, these statements obtain the\n   representations of the destination nodes on the previous layer. They are\n   then combined with neighbor aggregation in ``dgl.nn.SAGEConv`` layer.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>See the :doc:`custom message passing\n   tutorial <L4_message_passing>` for more details on how to\n   manipulate MFGs produced in this way, such as the usage\n   of ``num_dst_nodes``.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defining Training Loop\n----------------------\n\nThe following initializes the model and defines the optimizer.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "opt = torch.optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When computing the validation score for model selection, usually you can\nalso do neighbor sampling. To do that, you need to define another data\nloader.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "valid_dataloader = dgl.dataloading.NodeDataLoader(\n    graph, valid_nids, sampler,\n    batch_size=1024,\n    shuffle=False,\n    drop_last=False,\n    num_workers=0,\n    device=device\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following is a training loop that performs validation every epoch.\nIt also saves the model with the best validation accuracy into a file.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import tqdm\nimport sklearn.metrics\n\nbest_accuracy = 0\nbest_model_path = 'model.pt'\nfor epoch in range(10):\n    model.train()\n\n    with tqdm.tqdm(train_dataloader) as tq:\n        for step, (input_nodes, output_nodes, mfgs) in enumerate(tq):\n            # feature copy from CPU to GPU takes place here\n            inputs = mfgs[0].srcdata['feat']\n            labels = mfgs[-1].dstdata['label']\n\n            predictions = model(mfgs, inputs)\n\n            loss = F.cross_entropy(predictions, labels)\n            opt.zero_grad()\n            loss.backward()\n            opt.step()\n\n            accuracy = sklearn.metrics.accuracy_score(labels.cpu().numpy(), predictions.argmax(1).detach().cpu().numpy())\n\n            tq.set_postfix({'loss': '%.03f' % loss.item(), 'acc': '%.03f' % accuracy}, refresh=False)\n\n    model.eval()\n\n    predictions = []\n    labels = []\n    with tqdm.tqdm(valid_dataloader) as tq, torch.no_grad():\n        for input_nodes, output_nodes, mfgs in tq:\n            inputs = mfgs[0].srcdata['feat']\n            labels.append(mfgs[-1].dstdata['label'].cpu().numpy())\n            predictions.append(model(mfgs, inputs).argmax(1).cpu().numpy())\n        predictions = np.concatenate(predictions)\n        labels = np.concatenate(labels)\n        accuracy = sklearn.metrics.accuracy_score(labels, predictions)\n        print('Epoch {} Validation Accuracy {}'.format(epoch, accuracy))\n        if best_accuracy < accuracy:\n            best_accuracy = accuracy\n            torch.save(model.state_dict(), best_model_path)\n\n        # Note that this tutorial do not train the whole model to the end.\n        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conclusion\n----------\n\nIn this tutorial, you have learned how to train a multi-layer GraphSAGE\nwith neighbor sampling.\n\nWhat\u2019s next?\n------------\n\n-  :doc:`Stochastic training of GNN for link\n   prediction <L2_large_link_prediction>`.\n-  :doc:`Adapting your custom GNN module for stochastic\n   training <L4_message_passing>`.\n-  During inference you may wish to disable neighbor sampling. If so,\n   please refer to the `user guide on exact offline\n   inference <guide-minibatch-inference>`.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Thumbnail Courtesy: Stanford CS224W Notes\n# sphinx_gallery_thumbnail_path = '_static/blitz_1_introduction.png'"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}